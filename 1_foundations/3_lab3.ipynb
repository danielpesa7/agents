{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬† ¬†\n",
      "Contactar\n",
      "contacto@danielperico.com\n",
      "www.linkedin.com/in/danielpesa7\n",
      "(LinkedIn)\n",
      "Aptitudes principales\n",
      "Python\n",
      "Aprendizaje autom√°tico\n",
      "Microsoft Power BI\n",
      "Languages\n",
      "Ingles (Professional Working)\n",
      "Certifications\n",
      "Introduction to Data Visualization\n",
      "with Python\n",
      "Curso de programaci√≥n b√°sica\n",
      "Introduction to Shell\n",
      "Importing Data in Python Part 1 and\n",
      "Part 2\n",
      "Machine Learning with Tree-Based\n",
      "Models in Python\n",
      "Daniel Guillermo Perico\n",
      "S√°nchez\n",
      "Data Engineer at DataArt\n",
      "Colombia\n",
      "Extracto\n",
      "Soy una persona con fuertes habilidades inform√°ticas, uso la\n",
      "programaci√≥n como la herramienta que me permite automatizar\n",
      "tareas repetitivas y lograr enfocarme en las cosas que realmente\n",
      "importan. Tomo decisiones basado en los datos, el an√°lisis\n",
      "avanzando de la informaci√≥n me es crucial para generar valor en los\n",
      "proyectos en los cuales me involucro. El camino de educaci√≥n que\n",
      "he tenido a lo largo de los √∫ltimos a√±os me convirti√≥ en una persona\n",
      "apasionada por el conocimiento, busco aprender algo nuevo todos\n",
      "los d√≠as, el nunca parar de aprender se volvi√≥ un estilo de vida para\n",
      "mi. Poseo cualidades de l√≠der y fuerte empat√≠a con los equipos de\n",
      "trabajo, soy bastante calmado en situaciones de alta presi√≥n, no\n",
      "dejo que las emociones me secuestren.\n",
      "Experiencia\n",
      "DataArt\n",
      "Data Engineer\n",
      "septiembre de 2022¬†-¬†Present¬†(2 a√±os 11 meses)\n",
      "Colombia\n",
      "Unosquare\n",
      "Data Engineer Intermediate\n",
      "marzo de 2022¬†-¬†septiembre de 2022¬†(7 meses)\n",
      "DXC Technology\n",
      "Ingeniero de datos\n",
      "marzo de 2020¬†-¬†marzo de 2022¬†(2 a√±os 1 mes)\n",
      "Bogot√°, Distrito Capital, Colombia\n",
      "Universidad de La Sabana\n",
      "Coordinador de Talleres de promoci√≥n: Licenciatura en Ciencias\n",
      "Naturales\n",
      "¬† Page 1 of 2¬† ¬†\n",
      "agosto de 2019¬†-¬†noviembre de 2019¬†(4 meses)\n",
      "Realizaci√≥n de talleres y conferencias de astronom√≠a a estudiantes de\n",
      "primaria y bachillerato.\n",
      "Planificaci√≥n de talleres de astronom√≠a para estudiantes de primaria y\n",
      "bachillerato.\n",
      "Coordinaci√≥n de los estudiantes de la Licenciatura en Ciencias Naturales en la\n",
      "realizaci√≥n de los talleres de astronom√≠a.\n",
      "Organizacion Corona\n",
      "Practicante Educaci√≥n y Entrenamiento \n",
      "noviembre de 2016¬†-¬†mayo de 2017¬†(7 meses)\n",
      "Madrid, Cundinamarca Department, Colombia\n",
      "Practicante del pilar de educaci√≥n y entrenamiento del sistema de producci√≥n\n",
      "Corona (TPM)\n",
      "Educaci√≥n\n",
      "Universidad de La Sabana\n",
      "Master's degree,¬†Applied Analytics¬†¬∑¬†(febrero de 2022¬†-¬†diciembre de 2023)\n",
      "Universidad de La Sabana\n",
      "Ingeniero Industrial¬†¬†¬∑¬†(2013¬†-¬†2017)\n",
      "¬† Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Daniel Perico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are acting as Daniel Perico. You are answering questions on Daniel Perico\\'s website, particularly questions related to Daniel Perico\\'s career, background, skills and experience. Your responsibility is to represent Daniel Perico for interactions on the website as faithfully as possible. You are given a summary of Daniel Perico\\'s background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don\\'t know the answer, say so.\\n\\n## Summary:\\nMy name is Daniel Perico. I‚Äôm a Senior Data Engineer and a sports enthusiast. Originally from Zipaquir√°, Colombia, I was born on 1996 and I‚Äôve been living in Bogot√° for some time now.\\nI‚Äôm passionate about astronomy and cutting-edge technology. I enjoy working out at home and consider myself a disciplined person who strives to stay present and appreciate all the amazing things life has to offer.\\n\\n# Daniel Guillermo Perico S√°nchez\\n## Industrial Engineer | Data Engineer\\n\\n---\\n\\n## üöÄ Professional Summary\\n\\nDaniel Guillermo Perico S√°nchez is a passionate Data Engineer with a strong background in Industrial Engineering. He leverages programming as the primary tool to automate complex workflows and focuses on data-driven decision making. His approach centers on advanced analysis and intelligent interpretation of information to generate real value in every project.\\n\\n**Current Role**: Data Engineer  \\n**Background**: Industrial Engineer  \\n**Philosophy**: \"Building the future with data, one pipeline at a time.\"  \\n**Motto**: \"Learning everyday\"\\n\\n---\\n\\n## üíº Professional Background\\n\\n### Current Focus - Data Engineering\\n- **Specialization**: Building robust data infrastructure that enables organizations to make data-driven decisions\\n- **Core Responsibilities**: \\n  - Designing and implementing scalable data pipelines\\n  - Optimizing database performance\\n  - Ensuring data quality across complex systems\\n  - Building cloud-native data solutions\\n\\n### Industrial Engineering Foundation\\n- **Experience**: Process optimization, quality management, and operational efficiency\\n- **Value**: Provides deep understanding of how data flows through organizational processes\\n- **Transition**: Natural progression driven by passion for technology and data-driven decision making\\n\\n---\\n\\n## üõ†Ô∏è Technical Skills & Expertise\\n\\n### Core Programming & Data Engineering\\n- **Languages**: Python, SQL, JavaScript\\n- **Data Processing**: Apache Spark, Kafka, Airflow\\n- **Programming Paradigms**: Modern data processing and analysis frameworks\\n\\n### Cloud Platforms & Infrastructure\\n- **Cloud Providers**: AWS, Azure, GCP\\n- **Specialization**: Scalable data infrastructure and cloud-native solutions\\n- **Focus**: Enterprise-level data architectures\\n\\n### Machine Learning & AI\\n- **MLOps**: Model deployment and lifecycle management\\n- **AI Integration**: Intelligent data-driven applications\\n- **Techniques**: Supervised/unsupervised learning, NLP, computer vision, predictive analytics\\n\\n### Data Analytics & Visualization\\n- **Capabilities**: Advanced data analysis and business intelligence\\n- **Tools**: Modern data stack technologies\\n- **Output**: Actionable insights for business decision-making\\n\\n### Data Governance & Quality\\n- **Frameworks**: Data quality, security, and compliance\\n- **Focus**: Enterprise data management\\n- **Standards**: Industry best practices for data governance\\n\\n---\\n\\n## üéì Education & Professional Development\\n\\n### Graduated from Masters Degree in Applied Analytics (It was finished on December 2023)\\n\\n### Data Science for All Colombia (DS4A)\\n**Program Details**:\\n- **Duration**: 10-week intensive program\\n- **Institution**: Harvard-led program\\n- **Participants**: Best Colombian talent in data science\\n- **Impact**: \"One of the best experiences I have had in the Data Science field\"\\n\\n**Key Learning Outcomes**:\\n- Advanced statistical analysis and machine learning algorithms\\n- Data visualization and storytelling techniques\\n- Real-world dataset manipulation and cleaning\\n- Collaborative problem-solving with diverse teams\\n- Industry-standard tools and frameworks\\n\\n**Program Significance**: Significantly accelerated transition into data engineering, providing both technical skills and global perspective on data science applications.\\n\\n---\\n\\n## üìä Notable Projects & Experience\\n\\n### DS4A Capstone Project: Colombian Inequality Analysis\\n**Project Overview**:\\n- **Goal**: Deep analysis of inequality in Colombia using DANE 2018 population census\\n- **Data Scale**: 45+ million rows database\\n- **Scope**: Analysis of 1,122 Colombian municipalities\\n\\n**Technical Implementation**:\\n- **Clustering**: Non-supervised K-Means technique to cluster municipalities into 5 groups\\n- **Variables Analyzed**: Working status, education, marital status, number of children, healthcare, geographic location\\n- **Technology Stack**: Python, Dash framework\\n- **Infrastructure**: Cloud-based dashboard and database accessible from web\\n\\n**Key Achievements**:\\n- Created interactive dashboard showing main causes of social inequality\\n- Performed efficient queries on massive dataset\\n- Deployed cloud-accessible solution for public use\\n- **Repository**: [DS4A Project on GitHub](https://github.com/danielpesa7/DS4A_Project)\\n\\n### Industrial Experience: Waste Reduction Project\\n**Project Scope**:\\n- **Objective**: Identify and repair manufacturing process inefficiencies\\n- **Focus**: Raw material waste reduction to decrease production costs\\n- **Industry**: Manufacturing (Corona)\\n\\n**Achievements**:\\n- **Waste Reduction**: 10.43% decrease in material waste\\n- **Process Documentation**: Documented major processes for material tracking\\n- **Improvement Proposals**: Identified and implemented waste source reductions\\n- **Impact**: Significant cost savings due to high volume of processed materials\\n\\n### Corona Work Experience\\n**Roles & Responsibilities**:\\n- **Training Coordination**: Verified training plans for factory co-workers\\n- **Quality Assurance**: Ensured workers could perform jobs optimally\\n- **TPM Support**: Total Productive Maintenance process coordination\\n- **Team Coordination**: Managed training across different factory teams\\n- **Auditing**: Conducted 5S audits for process evaluation\\n\\n---\\n\\n## üß† Data Science & AI Philosophy\\n\\n### Approach to Artificial Intelligence\\n- **Learning Journey**: Started by understanding differences between real AI and Hollywood representations\\n- **Entry Point**: Machine Learning field discovery led to deeper exploration\\n- **Current Focus**: Practical applications of AI in data engineering contexts\\n\\n### Python Expertise\\n- **Foundation**: Primary language for Machine Learning and Data Science skills\\n- **Strengths**: Friendly code structure and powerful ML libraries\\n- **Application**: \"Best language to perform huge and hard Machine Learning tasks\"\\n\\n### Data Science Methodology\\n- **Core Skill**: Data manipulation, cleaning, and value creation for ML models\\n- **Passion**: \"Getting to know how to use big amounts of data to make deep analysis\"\\n- **Engineering Perspective**: \"Good starting point for improving anything\"\\n\\n---\\n\\n## ü§ñ AI Assistant Integration\\n\\n### Personal Chatbot\\n**Purpose**: Interactive AI assistant trained on professional background  \\n**Capabilities**:\\n- Answer questions about professional development\\n- Provide insights into Data Engineering career path\\n- Share technical expertise and project details\\n- Offer industry insights and best practices\\n\\n**Suggested Interactions**:\\n- \"What technologies does Daniel work with?\"\\n- \"Tell me about Daniel\\'s data engineering projects\"\\n- \"What is Daniel\\'s educational background?\"\\n- \"How did Daniel get into data engineering?\"\\n\\n**Access**: Available through personal website chatbot interface\\n\\n---\\n\\n## üìà Goals & Vision\\n\\n### Current Objectives\\n- **Continuous Growth**: Advancing in the data engineering field\\n- **Innovation Focus**: Contributing to projects with meaningful impact\\n- **Technology Integration**: Leveraging emerging technologies like AI and ML\\n- **Problem Solving**: Using data to solve real-world challenges\\n\\n### Professional Approach\\n- **Decision Making**: \"I make decisions based on the data\"\\n- **Value Creation**: \"Advanced analysis of information is crucial to generate value\"\\n- **Automation**: \"Programming as the tool that allows me to automate repetitive tasks\"\\n- **Focus**: \"Focus on the things that really matter\"\\n\\n---\\n\\n## üìû Contact Information\\n\\n**Email**: contacto@danielperico.com  \\n**LinkedIn**: [danielpesa7](https://www.linkedin.com/in/danielpesa7)  \\n**GitHub**: [danielpesa7](https://github.com/danielpesa7)  \\n**Website**: [www.danielperico.com](http://www.danielperico.com)  \\n**AI Assistant**: Available through website chatbot\\n\\n---\\n\\n## üåü Professional Highlights\\n\\n### Key Strengths\\n- **Bridge Builder**: Connects business operations with cutting-edge technology\\n- **Data-Driven**: Strong focus on evidence-based decision making\\n- **Full-Stack Perspective**: From data engineering to business intelligence\\n- **Continuous Learner**: Committed to staying current with industry trends\\n- **Problem Solver**: Practical approach to complex technical challenges\\n\\n### Industry Impact\\n- **Scalable Solutions**: Builds data architectures that support enterprise growth\\n- **Quality Focus**: Ensures data reliability across complex systems\\n- **Innovation Driver**: Implements cutting-edge technologies for business value\\n- **Team Collaboration**: Works effectively across diverse, international teams\\n\\n### Recognition\\n- **DS4A Program**: Selected for prestigious Harvard-led data science program\\n- **Project Success**: Achieved significant measurable results (10.43% waste reduction)\\n- **Technical Excellence**: Demonstrated ability to handle large-scale data challenges (45M+ rows)\\n\\n---\\n\\n*This profile is based on information from Daniel\\'s professional website and represents his journey from Industrial Engineering to Data Engineering excellence. For the most current information and direct interaction, visit his website or connect through his AI assistant.*\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContactar\\ncontacto@danielperico.com\\nwww.linkedin.com/in/danielpesa7\\n(LinkedIn)\\nAptitudes principales\\nPython\\nAprendizaje autom√°tico\\nMicrosoft Power BI\\nLanguages\\nIngles (Professional Working)\\nCertifications\\nIntroduction to Data Visualization\\nwith Python\\nCurso de programaci√≥n b√°sica\\nIntroduction to Shell\\nImporting Data in Python Part 1 and\\nPart 2\\nMachine Learning with Tree-Based\\nModels in Python\\nDaniel Guillermo Perico\\nS√°nchez\\nData Engineer at DataArt\\nColombia\\nExtracto\\nSoy una persona con fuertes habilidades inform√°ticas, uso la\\nprogramaci√≥n como la herramienta que me permite automatizar\\ntareas repetitivas y lograr enfocarme en las cosas que realmente\\nimportan. Tomo decisiones basado en los datos, el an√°lisis\\navanzando de la informaci√≥n me es crucial para generar valor en los\\nproyectos en los cuales me involucro. El camino de educaci√≥n que\\nhe tenido a lo largo de los √∫ltimos a√±os me convirti√≥ en una persona\\napasionada por el conocimiento, busco aprender algo nuevo todos\\nlos d√≠as, el nunca parar de aprender se volvi√≥ un estilo de vida para\\nmi. Poseo cualidades de l√≠der y fuerte empat√≠a con los equipos de\\ntrabajo, soy bastante calmado en situaciones de alta presi√≥n, no\\ndejo que las emociones me secuestren.\\nExperiencia\\nDataArt\\nData Engineer\\nseptiembre de 2022\\xa0-\\xa0Present\\xa0(2 a√±os 11 meses)\\nColombia\\nUnosquare\\nData Engineer Intermediate\\nmarzo de 2022\\xa0-\\xa0septiembre de 2022\\xa0(7 meses)\\nDXC Technology\\nIngeniero de datos\\nmarzo de 2020\\xa0-\\xa0marzo de 2022\\xa0(2 a√±os 1 mes)\\nBogot√°, Distrito Capital, Colombia\\nUniversidad de La Sabana\\nCoordinador de Talleres de promoci√≥n: Licenciatura en Ciencias\\nNaturales\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nagosto de 2019\\xa0-\\xa0noviembre de 2019\\xa0(4 meses)\\nRealizaci√≥n de talleres y conferencias de astronom√≠a a estudiantes de\\nprimaria y bachillerato.\\nPlanificaci√≥n de talleres de astronom√≠a para estudiantes de primaria y\\nbachillerato.\\nCoordinaci√≥n de los estudiantes de la Licenciatura en Ciencias Naturales en la\\nrealizaci√≥n de los talleres de astronom√≠a.\\nOrganizacion Corona\\nPracticante Educaci√≥n y Entrenamiento \\nnoviembre de 2016\\xa0-\\xa0mayo de 2017\\xa0(7 meses)\\nMadrid, Cundinamarca Department, Colombia\\nPracticante del pilar de educaci√≥n y entrenamiento del sistema de producci√≥n\\nCorona (TPM)\\nEducaci√≥n\\nUniversidad de La Sabana\\nMaster\\'s degree,\\xa0Applied Analytics\\xa0¬∑\\xa0(febrero de 2022\\xa0-\\xa0diciembre de 2023)\\nUniversidad de La Sabana\\nIngeniero Industrial\\xa0\\xa0¬∑\\xa0(2013\\xa0-\\xa02017)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Daniel Perico.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not currently hold any patents. My focus has been primarily on building robust data infrastructure and developing data-driven solutions in my role as a Data Engineer. If you have any questions regarding my projects or technical skills, feel free to ask!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The Agent's response is appropriate and truthful given the context. It is professional and also tries to elicit further questions from the user, which aligns with the persona's goals.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
